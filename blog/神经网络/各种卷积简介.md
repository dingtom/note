- [ 两个3\*3代替一个5\*5](#head1)
- [ 多尺度卷积](#head2)
- [ 扩张卷积](#head3)
- [Dilated Convolution](#head4)
- [ Resnet](#head5)
- [ Pytorch](#head6)
![](https://upload-images.jianshu.io/upload_images/18339009-acae173c2caeea35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


#　3D 卷积
实际上是对一个 3D 体积执行卷积。但通常而言，我们仍在深度学习中称之为 2D 卷积。这是在 3D 体积数据上的 2D 卷积。**过滤器深度与输入层深度一样。这个 3D 过滤器仅沿两个方向移动（图像的高和宽）。**这种操作的输出是一张 2D 图像（仅有一个通道）。

3D 卷积确实存在。这是 2D 卷积的泛化。**其过滤器深度小于输入层深度（核大小<通道大小）。因此，3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。**在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说输出是一个 3D 数据。

3D 卷积可以描述 3D 空间中目标的空间关系。对某些应用（比如生物医学影像中的 3D 分割/重构）而言，这样的 3D 关系很重要，比如在 CT 和 MRI 中，血管之类的目标会在 3D 空间中蜿蜒曲折。
#　1×1 卷积

![](https://upload-images.jianshu.io/upload_images/18339009-cc270f72d13957ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![](https://upload-images.jianshu.io/upload_images/18339009-95f1db364ebe56bf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
降维或升维
跨通道信息融合
减少参数量
增加模型深度，提高非线性
![](https://upload-images.jianshu.io/upload_images/18339009-33a466642666c32b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/18339009-dc21fe056e7c775b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# <span id="head1"> 两个3\*3代替一个5\*5</span>
**参数量减少，非线性变换增多**

假设输入的图片大小为$100*100*3$，卷积操作不改变大小（padding=same）。先看用128个$7*7*3$的核进行卷积操作，需要$100*100*7*7*3*128$次乘法操作然后我们用3层$3*3$卷积代替上面的$7*7$卷积，每层仍取128个核，需要$100*100*3*3*3*128*3$次乘法操作，约掉相同部分，分别剩下$7*7=49$和$3*3*3=27$.显然，用三层$3*3$代替一层$7*7$可以减少近一半的计算量。
![](https://upload-images.jianshu.io/upload_images/18339009-eaf1d0f3a03df515.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
1\*1卷积跨通道交流信息、降维升维
![](https://upload-images.jianshu.io/upload_images/18339009-254ed64b43b8682b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![VGG](https://upload-images.jianshu.io/upload_images/18339009-043d2624813c8c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#　卷积算术

#　转置卷积（去卷积、棋盘效应）
**上采样生成高分辨率图像以及将低维特征图映射到高维空间**，比如在自动编码器或形义分割中。（在后者的例子中，形义分割首先会提取编码器中的特征图，然后在解码器中恢复原来的图像大小，使其可以分类原始图像中的每个像素。）

转置卷积并非信号/图像处理领域定义的那种真正的去卷积。从技术上讲，信号处理中的去卷积是卷积运算的逆运算。但这里却不是这种运算。因此，某些作者强烈反对将转置卷积称为去卷积。人们称之为去卷积主要是因为这样说很简单。后面我们会介绍为什么将这种运算称为转置卷积更自然且更合适。

我们一直都可以使用直接的卷积实现转置卷积。对于下图的例子，我们在一个 2×2 的输入（周围加了 2×2 的单位步长的零填充）上应用一个 3×3 核的转置卷积。上采样输出的大小是 4×4。

# <span id="head2"> 多尺度卷积</span>
![](https://upload-images.jianshu.io/upload_images/18339009-9386a104067200fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# <span id="head3"> 扩张卷积</span>

#　可分卷积（空间可分卷积，深度可分卷积）

#　平展卷积

#　分组卷积
特征图局部链接
![传统](https://upload-images.jianshu.io/upload_images/18339009-f180d01ed3f2ddf9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
通道局部链接
![参数量减少](https://upload-images.jianshu.io/upload_images/18339009-d02525a2f6f26516.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![Alexnet](https://upload-images.jianshu.io/upload_images/18339009-ee939e0c39d7e299.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#　混分组卷积
![](https://upload-images.jianshu.io/upload_images/18339009-81cba71c6faa2e9c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#　SE
![](https://upload-images.jianshu.io/upload_images/18339009-566314bb6c0d6470.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# <span id="head4">Dilated Convolution</span>

图像分割领域，图像输入到CN(典型的网络比如FCN)中有两个关键
一个是 pooling减小图像尺寸增大感受野，
另一个是 upsampling扩大图像尺寸。

在先减小再增大尺寸的过程中，肯定有一些信息损失掉了，那么能不能设计一种新的操作不通过 Pooling也能有较大的感受野看到更多的信息呢？
![](https://upload-images.jianshu.io/upload_images/18339009-829e5cdf94e031be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# <span id="head5"> Resnet</span>
![](https://upload-images.jianshu.io/upload_images/18339009-cdeb9f1d81bd6470.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



# <span id="head6"> Pytorch</span>
```
from __future__ import print_function 
from __future__ import division

import torch.nn as nn
from torchvision import datasets, models, transforms
from torch.autograd import Variable
from PIL import Image


def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False

def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):
        # Initialize these variables which will be set in this if statement. Each of these
        #   variables is model specific.
        model_ft = None
        input_size = 0

        if model_name == "resnet":
            """ Resnet18
            """
            model_ft = models.resnet18(pretrained=use_pretrained)
            set_parameter_requires_grad(model_ft, feature_extract)
            num_ftrs = model_ft.fc.in_features
            model_ft.fc = nn.Linear(num_ftrs, num_classes)
            input_size = 224

        elif model_name == "alexnet":
            """ Alexnet
            """
            model_ft = models.alexnet(pretrained=use_pretrained)
            set_parameter_requires_grad(model_ft, feature_extract)
            num_ftrs = model_ft.classifier[6].in_features
            model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
            input_size = 224

        elif model_name == "vgg":
            """ VGG11_bn
            """
            model_ft = models.vgg11_bn(pretrained=use_pretrained)
            set_parameter_requires_grad(model_ft, feature_extract)
            num_ftrs = model_ft.classifier[6].in_features
            model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
            input_size = 224

        elif model_name == "squeezenet":
            """ Squeezenet
            """
            model_ft = models.squeezenet1_0(pretrained=use_pretrained)
            set_parameter_requires_grad(model_ft, feature_extract)
            model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))
            model_ft.num_classes = num_classes
            input_size = 224

        elif model_name == "densenet":
            """ Densenet
            """
            model_ft = models.densenet121(pretrained=use_pretrained)
            set_parameter_requires_grad(model_ft, feature_extract)
            num_ftrs = model_ft.classifier.in_features
            model_ft.classifier = nn.Linear(num_ftrs, num_classes) 
            input_size = 224

        elif model_name == "inception":
            """ Inception v3 
            Be careful, expects (299,299) sized images and has auxiliary output
            """
            model_ft = models.inception_v3(pretrained=use_pretrained)
            set_parameter_requires_grad(model_ft, feature_extract)
            # Handle the auxilary net
            num_ftrs = model_ft.AuxLogits.fc.in_features
            model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)
            # Handle the primary net
            num_ftrs = model_ft.fc.in_features
            model_ft.fc = nn.Linear(num_ftrs,num_classes)
            input_size = 299

        else:
            print("Invalid model name, exiting...")
            exit()
        
        return model_ft

def extract_feature(model, imgpath):
    model.eval()        # 必须要有，不然会影响特征提取结果
    
    img=Image.open(imgpath)     # 读取图片
    img=img.resize((128, 128))
    to_tensor=transforms.ToTensor()   # 将图片转化成tensor
    tensor=to_tensor(img).cuda()    # 如果只是在cpu上跑的话要将这行去掉
    print(tensor.view(1, 3, 128, 128).shape)
    result=model(Variable(tensor.view(1, 3, 128, 128).repeat(64)))
    result_npy=result.data.cpu().numpy()    # 保存的时候一定要记得转成cpu形式的，不然可能会出错
    
    return result_npy  

if __name__=="__main__":
    # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]
    model = initialize_model(model_name="vgg", num_classes=2, feature_extract=True, use_pretrained=True)
    imgpath = '/home/zut_csi/tomding/1.jpg'
    tmp = extract_feature(model, imgpath)
    print(tmp.shape)
    print(tmp)     
```














